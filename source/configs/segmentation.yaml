# Unified 3D Segmentation Pipeline Configuration

model:
  # Which model to use: 'openyolo3d' or 'mask3d'
  name: 'openyolo3d'

inference:
  # Frame sampling (higher = less memory, faster, but less accurate)
  frame_step: 10
  
  # Confidence threshold for detections
  conf_threshold: 0.1
  
  # Depth scale for OpenYOLO3D (default 1000.0 for typical depth sensors)
  depth_scale: 1000.0
  
  # Batch size for projection (OpenYOLO3D only)
  batch_size: 200000

vocabulary:
  # Vocabulary mode: 'lvis', 'coco', 'furniture', or 'custom'
  mode: 'furniture'
  
  # Custom classes (only used if mode='custom')
  custom_classes: []

output:
  # Output directory structure
  save_detailed_objects: true  # Save individual object PLYs
  save_scenegraph_format: true  # Save in SceneGraph-compatible format
  save_visualization: true  # Save colored mesh/point cloud
  generate_scene_graph: true  # Automatically generate scene graph after segmentation

openyolo3d:
  # OpenYOLO3D specific settings
  # Path relative to project root (steve_perception/)
  config_path: 'source/models/lib/OpenYOLO3D/pretrained/config.yaml'
  use_sam: false
  
mask3d:
  # Mask3D specific settings
  # Path relative to Mask3D library root
  checkpoint: 'saved/scannet200/scannet200_benchmark.ckpt'
  voxel_size: 0.02
  use_dbscan: false
